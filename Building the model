import pandas as pd
import numpy as np
import base64
import cv2
import tensorflow as tf
from tensorflow.keras import layers, models, regularizers
from sklearn.model_selection import train_test_split

# -----------------------------
# Load CSV
# -----------------------------
df = pd.read_csv("labeled_captcha_with_types.csv")

# -----------------------------
# Decode base64 â†’ images
# -----------------------------
images = []
labels = []

for i, row in df.iterrows():
    try:
        img_bytes = base64.b64decode(row['base64_string'])
        img_array = np.frombuffer(img_bytes, np.uint8)
        img = cv2.imdecode(img_array, cv2.IMREAD_GRAYSCALE)
        if img is None:
            continue
        img = cv2.resize(img, (100, 100))
        images.append(img)
        labels.append(row['label'])
    except Exception as e:
        print(f"Error at row {i}: {e}")

images = np.array(images, dtype="float32") / 255.0
images = np.expand_dims(images, -1)  # (N, 100, 100, 1)


# -----------------------------
# Load CSV
# -----------------------------
# Max length of captcha
max_len = 6

# Build charset
char_set = sorted(set("".join(labels)))
char_to_idx = {c: i for i, c in enumerate(char_set)}
idx_to_char = {i: c for c, i in char_to_idx.items()}
num_classes = len(char_set)

# Encode labels into one-hot
def encode_label(lbl):
    lbl_encoded = np.zeros((max_len, num_classes), dtype=np.float32)
    for i, ch in enumerate(lbl):
        if i < max_len:
            lbl_encoded[i, char_to_idx[ch]] = 1
    return lbl_encoded

y = np.array([encode_label(lbl) for lbl in labels])


# -----------------------------
# Load CSV
# -----------------------------

X_train, X_test, y_train, y_test, labels_train, labels_test = train_test_split(
    images, y, labels, test_size=0.1, random_state=42
)

# Split for multi-output
y_train_split = [y_train[:, i, :] for i in range(max_len)]
y_test_split  = [y_test[:, i, :]  for i in range(max_len)]

# -----------------------------
# Load CSV
# -----------------------------
input_img = layers.Input(shape=(100, 100, 1))

x = layers.Conv2D(32, (3, 3), activation="relu", padding="same",
                  kernel_regularizer=regularizers.l2(1e-4))(input_img)
x = layers.MaxPooling2D((2, 2))(x)
x = layers.Dropout(0.2)(x)

x = layers.Conv2D(64, (3, 3), activation="relu", padding="same",
                  kernel_regularizer=regularizers.l2(1e-4))(x)
x = layers.MaxPooling2D((2, 2))(x)
x = layers.Dropout(0.3)(x)

x = layers.Conv2D(128, (3, 3), activation="relu", padding="same",
                  kernel_regularizer=regularizers.l2(1e-4))(x)
x = layers.MaxPooling2D((2, 2))(x)
x = layers.Dropout(0.4)(x)

x = layers.Flatten()(x)
x = layers.Dense(512, activation="relu", kernel_regularizer=regularizers.l2(1e-4))(x)
x = layers.Dropout(0.5)(x)

# Multi-output heads (one per char position)
outputs = [layers.Dense(num_classes, activation="softmax", name=f"char_{i}")(x) for i in range(max_len)]

model = models.Model(inputs=input_img, outputs=outputs)
model.compile(optimizer="adam", loss="categorical_crossentropy", metrics=["accuracy"] * max_len) # Corrected metrics here
model.summary()

# -----------------------------
# Load CSV
# -----------------------------

history = model.fit(
    X_train, y_train_split,
    epochs=50, batch_size=32,
    validation_data=(X_test, y_test_split)
)
# -----------------------------
# Load CSV
# -----------------------------
def evaluate_full_captcha_accuracy(model, X_test, y_test_split, labels_test):
    preds = model.predict(X_test)
    pred_indices = np.stack([np.argmax(p, axis=1) for p in preds], axis=1)
    true_indices = np.stack([np.argmax(t, axis=1) for t in y_test_split], axis=1)

    correct = np.all(pred_indices == true_indices, axis=1)
    full_acc = np.mean(correct)

    print(f"Full Captcha Accuracy: {full_acc:.4f} ({correct.sum()}/{len(correct)})")

    for i in range(5):  # show a few mismatches
        if not correct[i]:
            pred_str = "".join([idx_to_char[idx] for idx in pred_indices[i]])
            print(f"True: {labels_test[i]}, Pred: {pred_str}")

    return full_acc

acc = evaluate_full_captcha_accuracy(model, X_test, y_test_split, labels_test)

# ----------------------------------------------------------
# Using learning rate scheduler to improve accuracy
# ----------------------------------------------------------

from tensorflow.keras.callbacks import ReduceLROnPlateau

# Define the learning rate scheduler
reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=0.0001)

# Recompile the model with the same optimizer and loss functions
# model.compile(optimizer="adam", loss="categorical_crossentropy", metrics=["accuracy"] * max_len) # No need to recompile

# Train the model with the learning rate scheduler callback
history_with_lr = model.fit(
    X_train, y_train_split,
    epochs=50, # Train for 50 epochs
    batch_size=32,
    validation_data=(X_test, y_test_split),
    callbacks=[reduce_lr]
)

# ----------------------------------------------------------
# Using learning rate scheduler to improve accuracy
# ----------------------------------------------------------

def evaluate_full_captcha_accuracy(model, X_test, y_test_split, labels_test):
    preds = model.predict(X_test)
    pred_indices = np.stack([np.argmax(p, axis=1) for p in preds], axis=1)
    true_indices = np.stack([np.argmax(t, axis=1) for t in y_test_split], axis=1)

    correct = np.all(pred_indices == true_indices, axis=1)
    full_acc = np.mean(correct)

    print(f"Full Captcha Accuracy: {full_acc:.4f} ({correct.sum()}/{len(correct)})")

    for i in range(5):  # show a few mismatches
        if not correct[i]:
            pred_str = "".join([idx_to_char[idx] for idx in pred_indices[i]])
            print(f"True: {labels_test[i]}, Pred: {pred_str}")

    return full_acc

acc = evaluate_full_captcha_accuracy(model, X_test, y_test_split, labels_test)

# ----------------------------------------------------------
# Using learning rate scheduler to improve accuracy
# ----------------------------------------------------------

import matplotlib.pyplot as plt

# Get the history from the last training run
history = history_with_lr

# Plot training and validation loss
plt.figure(figsize=(12, 6))
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Training and Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.show()

# Plot training and validation accuracy for each character position
plt.figure(figsize=(12, 10))
for i in range(max_len):
    plt.plot(history.history[f'char_{i}_accuracy'], label=f'Training Accuracy (Char {i})')
    plt.plot(history.history[f'val_char_{i}_accuracy'], label=f'Validation Accuracy (Char {i})')

plt.title('Training and Validation Accuracy per Character')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

# ----------------------------------------------------------
# Using learning rate scheduler to improve accuracy
# ----------------------------------------------------------

model.save('captcha_recognition_model.keras')
